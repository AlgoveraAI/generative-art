{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1c09dfc",
   "metadata": {},
   "source": [
    "# Compute to Data for Generative Art\n",
    "The 3-C2D-flow-ocean notebook provides a good first step towards getting your head around C2D, but it is not configured to the C2D flow data scientists might use when training an ML model. In this notebook and those that follow, we'll work on the same steps but this time specifically for the Cryptopunks generative art project. The steps are separated for modularity and to provide a template that can be used in subsequent projects\n",
    "\n",
    "### Notes from the original C2D Notebook:\n",
    "- **3. Alice publishes a dataset** is not needed here (this is relevant for teams who want to publish datasets, not teams who want to use existing datasets to train ML models)\n",
    "- **4. Alice publishes an algorithm** is relevant (we're going to publish the ML model as an algorithm)\n",
    "- **5. Bob acquires datatokens for data and algorithm** is only needed to get the datatokens for the data (we already own the tokens for the algorithm)\n",
    "- **6. Bob starts a compute job** is relevant (we need to specify where we want to train the algorithm on. Initially, the simplest option is connecting to an AWS compute instance, later on to decentralized computer providers such as the Raven Protocol)\n",
    "- **7. Bob monitors logs / algorithm output** is relevant\n",
    "\n",
    "#### Additional steps not covered in C2D Notebook:\n",
    "- testing the trained model\n",
    "- running inference\n",
    "- retraining the model (after change of architecture/hyperparameter tuning)\n",
    "- publishing the trained model on the marketplace\n",
    "- using the model from the marketplace to get a new Cryptopunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a271b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "import _init_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd640a5",
   "metadata": {},
   "source": [
    "You can publish an algorithm through the GUI. Check out our first hacking session where we run through [this](https://www.youtube.com/watch?v=AThhcQrjRQk&list=PLgIrgqrkZC93qCxZFx_kWzk2vFdvgJjJI&t=35m20s) process. Here we'll use the Ocean python library. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c395ca97",
   "metadata": {},
   "source": [
    "We need to connect to the Ethereum network via an Ethereum node. We have set the config parameters for you in a config file. We are currently using [Infura](https://infura.io) for this but will be migrating to a full Ethereum Erigon node asap for increased decentralization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61f13f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.network_url = 'https://rinkeby.infura.io/v3/d163c48816434b0bbb3ac3925d6c6c80'\n",
      "config.block_confirmations = 0\n",
      "config.metadata_cache_uri = 'https://aquarius.oceanprotocol.com'\n",
      "config.provider_url = 'https://provider.rinkeby.oceanprotocol.com'\n"
     ]
    }
   ],
   "source": [
    "from ocean_lib.ocean.ocean import Ocean\n",
    "from ocean_lib.config import Config\n",
    "\n",
    "config = Config('config.ini')\n",
    "ocean = Ocean(config)\n",
    "\n",
    "print(f\"config.network_url = '{config.network_url}'\")\n",
    "print(f\"config.block_confirmations = {config.block_confirmations.value}\")\n",
    "print(f\"config.metadata_cache_uri = '{config.metadata_cache_uri}'\")\n",
    "print(f\"config.provider_url = '{config.provider_url}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f37e01",
   "metadata": {},
   "source": [
    "Next, export your private key from your metamask wallet. We highly recommend doing this with a wallet that has no real tokens in it (only Rinkeby tokens). For more info on private keys, see [this](https://github.com/oceanprotocol/ocean.py/blob/main/READMEs/wallets.md) from the ocean.py documentation: \n",
    "\n",
    "*The whole point of crypto wallets is to store private keys. Wallets have various tradeoffs of cost, convienence, and security. For example, hardware wallets tend to be more secure but less convenient and not free. It can also be useful to store private keys locally on your machine, for testing, though only with a small amount of value at stake (keep the risk down). Do not store your private keys on anything public, unless you want your tokens to disappear. For example, don't store your private keys in GitHub or expose them on frontend webpage code.*\n",
    "\n",
    "With this in mind, you can directly load your private key into the notebook. We use an envvar rather than storing it in code that might be pushed to a repo. We copy this in for a new session (you may need to restart the notebook server). Here's how we export an environmental variable using an example key (replace this with your actual private key.). From your console:\n",
    "\n",
    "```console\n",
    "export MY_TEST_KEY=0xaefd8bc8725c4b3d15fbe058d0f58f4d852e8caea2bf68e0f73acb1aeec19baa\n",
    "```\n",
    "\n",
    "Now initialize your wallet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "72b9853a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public address = '0x2338e4e94AEe1817701F65f2c751f7c844b0e43b'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from ocean_lib.web3_internal.wallet import Wallet\n",
    "\n",
    "wallet = Wallet(ocean.web3, os.getenv('MY_TEST_KEY'), transaction_timeout=20, block_confirmations=config.block_confirmations)\n",
    "\n",
    "print(f\"public address = '{wallet.address}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d813310f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALG_datatoken.address = '0xE2e123115d5758Dd4C6F434E1c142e72ed8B2820'\n"
     ]
    }
   ],
   "source": [
    "from ocean_lib.web3_internal.currency import to_wei\n",
    "\n",
    "# Publish ALG datatoken\n",
    "ALG_datatoken = ocean.create_data_token('ARTGEN0', 'ARTGEN0', wallet, blob=ocean.config.metadata_cache_uri)\n",
    "ALG_datatoken.mint(wallet.address, to_wei(100), wallet)\n",
    "print(f\"ALG_datatoken.address = '{ALG_datatoken.address}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60cdfa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool has 1E+2 ARTGEN0 (100000000000000000000 wei).\n"
     ]
    }
   ],
   "source": [
    "from ocean_lib.web3_internal.currency import pretty_ether_and_wei\n",
    "print(f\"Pool has {pretty_ether_and_wei(ALG_datatoken.balanceOf(wallet.address), ALG_datatoken.symbol())}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e86443a",
   "metadata": {},
   "source": [
    "## Alice publishes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c7f46d",
   "metadata": {},
   "source": [
    "Ocean Protocol provides some basic Dockerfiles in their [profile](https://hub.docker.com/r/oceanprotocol/algo_dockers) on Dockerhub. In the third notebook, we used the PyTorch library to train a simple generative model, which isn't installed in the Ocean Protocol containers. Hence, we will use a custom Dockerfile that we have pushed to our new Algovera profile on [Dockerhub](https://hub.docker.com/r/algovera/algo_dockers/tags). We use the image name and tag in the `container` part of the algorithm metadata.\n",
    "This docker image needs to have basic support for dependency installation e.g. in the case of Python, OS-level library installations, pip installations etc.\n",
    "Take a look at the [Ocean tutorials](https://docs.oceanprotocol.com/tutorials/compute-to-data-algorithms/) to learn more about docker image publishing.\n",
    "For the url, we want raw text rather than html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60abf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Parameters\n",
    "image: str = \"algovera/algo_dockers\" \n",
    "tag: str = \"generative-art\"\n",
    "url: str = \"https://raw.githubusercontent.com/AlgoveraAI/generative-art/main/4-dcgan-c2d.py\"\n",
    "name: str = \"Generative Algorithm: DCGAN\"\n",
    "author: str = \"AlgoveraAI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9d707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify metadata and service attributes, for \"GPR\" algorithm script.\n",
    "# In same location as Branin test dataset. GPR = Gaussian Process Regression.\n",
    "ALG_metadata =  {\n",
    "    \"main\": {\n",
    "        \"type\": \"algorithm\",\n",
    "        \"algorithm\": {\n",
    "            \"language\": \"python\",\n",
    "            \"format\": \"docker-image\",\n",
    "            \"version\": \"0.1\",\n",
    "            \"container\": {\n",
    "              \"entrypoint\": \"python $ALGO\",\n",
    "              \"image\": image,\n",
    "              \"tag\": tag\n",
    "            }\n",
    "        },\n",
    "        \"files\": [\n",
    "    {\n",
    "        \"url\": url,\n",
    "        \"index\": 0,\n",
    "        \"contentType\": \"text/text\",\n",
    "      }\n",
    "    ],\n",
    "    \"name\": name, \"author\": author, \"license\": \"CC0\",\n",
    "    \"dateCreated\": \"2021-12-02T15:00:00Z\"\n",
    "    }\n",
    "}\n",
    "\n",
    "ALG_service_attributes = {\n",
    "        \"main\": {\n",
    "            \"name\": \"ALG_dataAssetAccessServiceAgreement\",\n",
    "            \"creator\": wallet.address,\n",
    "            \"timeout\": 3600 * 24,\n",
    "            \"datePublished\": \"2020-01-28T10:55:11Z\",\n",
    "            \"cost\": 1.0, # <don't change, this is obsolete>\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17f44661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signing message with nonce 0: 0xE2e123115d5758Dd4C6F434E1c142e72ed8B2820, account=0x2338e4e94AEe1817701F65f2c751f7c844b0e43b\n",
      "ALG did = 'did:op:E2e123115d5758Dd4C6F434E1c142e72ed8B2820'\n"
     ]
    }
   ],
   "source": [
    "# Set up a service provider. We'll use this same provider for ALG\n",
    "from ocean_lib.data_provider.data_service_provider import DataServiceProvider\n",
    "provider_url = DataServiceProvider.get_url(ocean.config)\n",
    "# returns \"http://localhost:8030\"\n",
    "\n",
    "# Calc DATA service compute descriptor\n",
    "from ocean_lib.services.service import Service\n",
    "from ocean_lib.common.agreements.service_types import ServiceTypes\n",
    "\n",
    "# Calc ALG service access descriptor. We use the same service provider as DATA\n",
    "ALG_access_service = Service(\n",
    "    service_endpoint=provider_url,\n",
    "    service_type=ServiceTypes.CLOUD_COMPUTE,\n",
    "    attributes=ALG_service_attributes\n",
    ")\n",
    "\n",
    "# Publish metadata and service info on-chain\n",
    "ALG_ddo = ocean.assets.create(\n",
    "  metadata=ALG_metadata, # {\"main\" : {\"type\" : \"algorithm\", ..}, ..}\n",
    "  publisher_wallet=wallet,\n",
    "  services=[ALG_access_service],\n",
    "  data_token_address=ALG_datatoken.address)\n",
    "print(f\"ALG did = '{ALG_ddo.did}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6deb86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "signing message with nonce 16: 0x1fDe09d7056F5A077e67C9170998855dbE0DE62D, account=0xD438208197a0C552ED04e5e51695EC695E30C284\n",
      "ALG did = 'did:op:1fDe09d7056F5A077e67C9170998855dbE0DE62D'\n"
     ]
    }
   ],
   "source": [
    "# Publish metadata and service info on-chain\n",
    "ALG_ddo = ocean.assets.create(\n",
    "  metadata=ALG_metadata, # {\"main\" : {\"type\" : \"algorithm\", ..}, ..}\n",
    "  publisher_wallet=wallet,\n",
    "  service_descriptors=[ALG_access_service_descriptor],\n",
    "  data_token_address=ALG_datatoken.address)\n",
    "print(f\"ALG did = '{ALG_ddo.did}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c64355c",
   "metadata": {},
   "source": [
    "At this point you will need to request that the data provider approves your code as a trusted algorithm on the dataset. For example, if you reach out to Algovera about one of our datasets, we will approve your request quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f16e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
