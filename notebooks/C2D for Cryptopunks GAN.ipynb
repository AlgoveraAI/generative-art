{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a838f0f8",
   "metadata": {},
   "source": [
    "# Compute to Data for Generative Art\n",
    "This notebook is a continuation of the C2D notebook but this time specifically for the Cryptopunks generative art project.\n",
    "\n",
    "Note: the code is currently not going to run, the goal of this notebook is to provide a template that can be used for the generative art GAN and any subsequent projects\n",
    "\n",
    "### Notes from the original C2D Notebook:\n",
    "- **3. Alice publishes a dataset** is not needed here (this is relevant for teams who want to publish datasets, not teams who want to use existing datasets to train ML models)\n",
    "- **4. Alice publishes an algorithm** is relevant (we're going to publish the ML model as an algorithm)\n",
    "- **5. Bob acquires datatokens for data and algorithm** is only needed to get the datatokens for the data (we already own the tokens for the algorithm)\n",
    "- **6. Bob starts a compute job** is relevant (we need to specify where we want to train the algorithm on. Initially, the simplest option is connecting to an AWS compute instance, later on to decentralized computer providers such as the Raven Protocol)\n",
    "- **7. Bob monitors logs / algorithm output** is relevant\n",
    "\n",
    "#### Additional steps not covered in C2D Notebook:\n",
    "- testing the trained model\n",
    "- running inference\n",
    "- retraining the model (after change of architecture/hyperparameter tuning)\n",
    "- publishing the trained model on the marketplace\n",
    "- using the model from the marketplace to get a new Cryptopunk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895a520a",
   "metadata": {},
   "source": [
    "## Publishing the Generative Art algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "742de705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Parameters\n",
    "wallet: str # our wallet address (for having ownership of the algorithm & buying dataset from Ocean Market)\n",
    "entrypoint: str # The Docker entrypoint. $ALGO is a macro that gets replaced inside the compute job, depending where your algorithm code is downloaded.\n",
    "image: str # the Docker image name\n",
    "tag: str # the Docker image tag\n",
    "url: str = \"https://raw.githubusercontent.com/AlgoveraAI/generative-art/main/cp_gan.py\"\n",
    "name: str = \"cp_gan\"\n",
    "author: str = \"Algovera\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d557a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Publish ALG datatoken\n",
    "ALG_datatoken = ocean.create_data_token('ALG1', 'ALG1', wallet, blob=ocean.config.metadata_cache_uri)\n",
    "ALG_datatoken.mint(wallet.address, to_wei(100), wallet)\n",
    "print(f\"ALG_datatoken.address = '{ALG_datatoken.address}'\")\n",
    "\n",
    "# Specify metadata and service attributes, for \"GPR\" algorithm script.\n",
    "# In same location as Branin test dataset. GPR = Gaussian Process Regression.\n",
    "ALG_metadata =  {\n",
    "    \"main\": {\n",
    "        \"type\": \"algorithm\",\n",
    "        \"algorithm\": {\n",
    "            \"language\": \"python\",\n",
    "            \"format\": \"docker-image\",\n",
    "            \"version\": \"0.1\",\n",
    "            \"container\": {\n",
    "              \"entrypoint\": entrypoint,\n",
    "              \"image\": image,\n",
    "              \"tag\": tag\n",
    "            }\n",
    "        },\n",
    "        \"files\": [\n",
    "      {\n",
    "        \"url\": url,\n",
    "        \"index\": 0,\n",
    "        \"contentType\": \"text/text\",\n",
    "      }\n",
    "    ],\n",
    "    \"name\": name, \"author\": author, \"license\": \"CC0\",\n",
    "    \"dateCreated\": \"2020-01-28T10:55:11Z\"\n",
    "    }\n",
    "}\n",
    "ALG_service_attributes = {\n",
    "        \"main\": {\n",
    "            \"name\": \"ALG_dataAssetAccessServiceAgreement\",\n",
    "            \"creator\": wallet.address,\n",
    "            \"timeout\": 3600 * 24,\n",
    "            \"datePublished\": \"2020-01-28T10:55:11Z\",\n",
    "            \"cost\": 1.0, # <don't change, this is obsolete>\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Calc ALG service access descriptor. We use the same service provider as DATA\n",
    "ALG_access_service = Service(\n",
    "    service_endpoint=provider_url,\n",
    "    service_type=ServiceTypes.CLOUD_COMPUTE,\n",
    "    attributes=ALG_service_attributes\n",
    ")\n",
    "\n",
    "# Publish metadata and service info on-chain\n",
    "ALG_ddo = ocean.assets.create(\n",
    "  metadata=ALG_metadata, # {\"main\" : {\"type\" : \"algorithm\", ..}, ..}\n",
    "  publisher_wallet=wallet,\n",
    "  services=[ALG_access_service],\n",
    "  data_token_address=ALG_datatoken.address)\n",
    "print(f\"ALG did = '{ALG_ddo.did}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0441f21",
   "metadata": {},
   "source": [
    "## Getting Datatokens for the Cryptopunks dataset\n",
    "The C2D notebook had the private keys of both Alice and Bob. This time, we just have our own private key and we want to buy datatokens for the [Cryptopunks dataset](https://market.oceanprotocol.com/asset/did:op:C9D0568838fa670baEe7195Ea443b32EfCAc2281).\n",
    "\n",
    "For this, we use the [Ocean Market flow](https://github.com/oceanprotocol/ocean.py/blob/main/READMEs/marketplace-flow.md).\n",
    "\n",
    "Note: Take a look at the Cryptopunks datatoken [here](https://rinkeby.etherscan.io/token/0xC9D0568838fa670baEe7195Ea443b32EfCAc2281)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90073e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Parameters\n",
    "\n",
    "# from the previous notebooks, your environment should store some test private keys\n",
    "private_key: str = os.getenv('TEST_KEY') # note: do NOT store your real private keys anywhere on your machine\n",
    "token_address: str = \"0xC9D0568838fa670baEe7195Ea443b32EfCAc2281\" # address of the Cryptopunks datatoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7cde08",
   "metadata": {},
   "outputs": [],
   "source": [
    "wallet = Wallet(ocean.web3, private_key, config.block_confirmations, config.transaction_timeout)\n",
    "print(f\"wallet.address = '{wallet.address}'\")\n",
    "\n",
    "#Verify that we have ganache ETH\n",
    "assert ocean.web3.eth.get_balance(wallet.address) > 0, \"need ganache ETH\"\n",
    "\n",
    "#Verify that we have ganache OCEAN\n",
    "assert OCEAN_token.balanceOf(wallet.address) > 0, \"need ganache OCEAN\"\n",
    "\n",
    "#We buy 1.0 datatokens - the amount needed to consume the dataset.\n",
    "data_token = ocean.get_data_token(token_address)\n",
    "ocean.pool.buy_data_tokens(\n",
    "    pool_address,\n",
    "    amount=to_wei(1), # buy 1.0 datatoken\n",
    "    max_OCEAN_amount=to_wei(10), # pay up to 10.0 OCEAN\n",
    "    from_wallet=wallet\n",
    ")\n",
    "\n",
    "# Check we have the datatoken\n",
    "from ocean_lib.web3_internal.currency import pretty_ether_and_wei\n",
    "print(f\"I have {pretty_ether_and_wei(data_token.balanceOf(wallet.address), data_token.symbol())}.\")\n",
    "\n",
    "assert data_token.balanceOf(wallet.address) >= to_wei(1), \"I didn't get 1.0 datatokens\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639da17",
   "metadata": {},
   "source": [
    "## Running a compute job on the dataset\n",
    "Now that we have the datatoken for the Cryptopunks dataset and the datatokens for our algorithm, we can run a compute job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d29f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_did = DATA_ddo.did  # for convenience\n",
    "ALG_did = ALG_ddo.did\n",
    "DATA_DDO = ocean.assets.resolve(DATA_did)  # make sure we operate on the updated and indexed metadata_cache_uri versions\n",
    "ALG_DDO = ocean.assets.resolve(ALG_did)\n",
    "\n",
    "compute_service = DATA_DDO.get_service('compute')\n",
    "algo_service = ALG_DDO.get_service('access')\n",
    "\n",
    "from ocean_lib.web3_internal.constants import ZERO_ADDRESS\n",
    "from ocean_lib.models.compute_input import ComputeInput\n",
    "\n",
    "# order & pay for dataset\n",
    "dataset_order_requirements = ocean.assets.order(\n",
    "    DATA_did, wallet.address, service_type=compute_service.type\n",
    ")\n",
    "DATA_order_tx_id = ocean.assets.pay_for_service(\n",
    "        ocean.web3,\n",
    "        dataset_order_requirements.amount,\n",
    "        dataset_order_requirements.data_token_address,\n",
    "        DATA_did,\n",
    "        compute_service.index,\n",
    "        ZERO_ADDRESS,\n",
    "        bob_wallet,\n",
    "        dataset_order_requirements.computeAddress,\n",
    "    )\n",
    "\n",
    "# order & pay for algo (we're the owner so this might be a bit different)\n",
    "algo_order_requirements = ocean.assets.order(\n",
    "    ALG_did, wallet.address, service_type=algo_service.type\n",
    ")\n",
    "ALG_order_tx_id = ocean.assets.pay_for_service(\n",
    "        ocean.web3,\n",
    "        algo_order_requirements.amount,\n",
    "        algo_order_requirements.data_token_address,\n",
    "        ALG_did,\n",
    "        algo_service.index,\n",
    "        ZERO_ADDRESS,\n",
    "        bob_wallet,\n",
    "        algo_order_requirements.computeAddress,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4823f55a",
   "metadata": {},
   "source": [
    "Now we need to specify the compute input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4555c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_inputs = [ComputeInput(DATA_did, DATA_order_tx_id, compute_service.index)]\n",
    "job_id = ocean.compute.start(\n",
    "    compute_inputs,\n",
    "    bob_wallet,\n",
    "    algorithm_did=ALG_did,\n",
    "    algorithm_tx_id=ALG_order_tx_id,\n",
    "    algorithm_data_token=ALG_datatoken.address\n",
    ")\n",
    "print(f\"Started compute job with id: {job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d61d28",
   "metadata": {},
   "source": [
    "## Logging the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc7068",
   "metadata": {},
   "outputs": [],
   "source": [
    "ocean.compute.status(DATA_did, job_id, bob_wallet) # rerun multiple times until output {'ok': True, 'status': 70, 'statusText': 'Job finished'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad869653",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ocean.compute.result_file(DATA_did, job_id, 1, bob_wallet)  # 0 index, means we retrieve the results from the first dataset index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c8016c",
   "metadata": {},
   "source": [
    "## Model test, inference, improvements\n",
    "WIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5ea640",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "algovera",
   "language": "python",
   "name": "algovera"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
